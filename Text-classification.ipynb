{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8srTskgfslvH"
      },
      "outputs": [],
      "source": [
        "# Импорт модулей"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2 as cv\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "from collections import Counter\n",
        "\n",
        "from tensorflow import keras\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "DCi_AVd9tBp_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#импорт датасета"
      ],
      "metadata": {
        "id": "TvK0RP9CyYJ_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "QZkk0e8WyiWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/gdrive/MyDrive/neural-network-datasets/text-style-dataset.zip"
      ],
      "metadata": {
        "id": "eXwNa5Kk3mTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = 'text-style-dataset'"
      ],
      "metadata": {
        "id": "4fcFN6Ht5rG9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_normal_array(arrays):\n",
        "  resultArray = []\n",
        "  for array in arrays:\n",
        "    res = []\n",
        "    for ar in array:\n",
        "      res.append(ar[0])\n",
        "    resultArray.append(res)\n",
        "  return resultArray"
      ],
      "metadata": {
        "id": "L_qB8Xv8i-rY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_arrays(arrays):\n",
        "    padded_arrays = []\n",
        "    target_length = max([len(seq) for seq in arrays])\n",
        "    for array in arrays:\n",
        "        padded_array = list(array)\n",
        "        while len(padded_array) < target_length:\n",
        "            padded_array.append([0])\n",
        "        padded_arrays.append(padded_array)\n",
        "    return padded_arrays"
      ],
      "metadata": {
        "id": "vPC_SLEQZiLK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_words(input): \n",
        " # lowercase everything to standardize it \n",
        " input = input.lower() \n",
        " # instantiate the tokenizer \n",
        " tokenizer = RegexpTokenizer(r'\\w+') \n",
        " tokens = tokenizer.tokenize(input) \n",
        " return \" \".join(tokens) \n"
      ],
      "metadata": {
        "id": "_5X54Iud_LYY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(DATASET_PATH):\n",
        "    text_data_array = []\n",
        "    class_name = []\n",
        "    for directory in os.listdir(DATASET_PATH):\n",
        "        for file in os.listdir(os.path.join(DATASET_PATH, directory)):\n",
        "            text_path = os.path.join(DATASET_PATH, directory, file)\n",
        "            file = open(text_path, encoding='utf-8', mode='r')\n",
        "            text = file.read()\n",
        "            # Токенизируем текст (разбиваем на слова)\n",
        "            tokens = tokenize_words(text) \n",
        "            # Создаем словарь, который сопоставляет каждому уникальному слову в тексте его индекс\n",
        "            word_counts = Counter([word for line in tokens for word in line])\n",
        "            vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "            vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
        "            # Преобразуем текст в числовое представление\n",
        "            int_text = [[vocab_to_int[word] for word in line] for line in tokens]\n",
        "\n",
        "            text_data_array.append( [[vocab_to_int[word] for word in line] for line in tokens])\n",
        "            class_name.append(directory)\n",
        "    text_data_array = pad_arrays(text_data_array)\n",
        "    text_data_array = get_normal_array(text_data_array)\n",
        "    return text_data_array, class_name"
      ],
      "metadata": {
        "id": "RWBBB2Al9EpQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_TEXT, DATA_LABELS = create_dataset(DATASET) #создание датасета из папки с файлами"
      ],
      "metadata": {
        "id": "EGhWt8lSB2dh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = np.unique(DATA_LABELS)\n",
        "target_dict_train = {k: v for v, k in enumerate(np.unique(DATA_LABELS))}\n",
        "DATA_LABELS = [target_dict_train[DATA_LABELS[i]] for i in range(len(DATA_LABELS))]"
      ],
      "metadata": {
        "id": "MEtfjKKIB2gD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#разделение выборок и предварительная обработка данных"
      ],
      "metadata": {
        "id": "AFNbrsYQtuVt"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(DATA_TEXT, DATA_LABELS, test_size = 0.25, random_state = 12)\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "tTIaBhj3w0d5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#создание модели и добавление в неё слоёв"
      ],
      "metadata": {
        "id": "zLjYOqcVw1AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(691, 128), \n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(2,'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "B_2VNqhkhiG7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#компиляция модели"
      ],
      "metadata": {
        "id": "VF4yjT2_hiJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gCDjQYUWhiMS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#вывод информации о модели"
      ],
      "metadata": {
        "id": "hVdbdxmcqn11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "iNIxPHaNhiPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#обучение"
      ],
      "metadata": {
        "id": "EfJF-b68hiRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs = 100)"
      ],
      "metadata": {
        "id": "pGjB8AGKhiUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test) #точность определения по тестовым данным\n",
        "print('Test accuracy: ', test_accuracy)"
      ],
      "metadata": {
        "id": "l3KU5f02hiXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#предсказывание по тестовой выборке"
      ],
      "metadata": {
        "id": "O7WCE_5ShiZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "id": "li1tISKLgMyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_of_prediction = 0 #индекс изображения тестовой выборки (можно поменять для демонстрации различных предсказаний)"
      ],
      "metadata": {
        "id": "H9PtOSu7huLK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Neural network\\'s prediction is a', class_names[np.argmax(predictions[index_of_prediction])])"
      ],
      "metadata": {
        "id": "3UAN5PaKgT_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('right answer is a', class_names[np.argmax(y_test[index_of_prediction])])"
      ],
      "metadata": {
        "id": "hmQAClXCgy26"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}